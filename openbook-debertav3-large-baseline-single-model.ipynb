{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# OpenBook DeBERTaV3-Large Baseline\n\nHi! This notebook is a merge of the following approaches:\n\n**OpenBook Approach**\n- https://www.kaggle.com/code/quangbk/open-book-llm-science-exam-reduced-ram-usage\n- https://www.kaggle.com/code/jjinho/open-book-llm-science-exam\n\n***DeBERTaV3-Large with extra data***\n- https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training\n\nThis both leverages the the multi-choice implementation of HuggingFace library and the context retrieval of the openbook approach. It can be extended with the utilization of billion parameter LLMs and better retrieval methods.","metadata":{}},{"cell_type":"code","source":"# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-14T10:07:16.129442Z","iopub.status.busy":"2023-08-14T10:07:16.128308Z","iopub.status.idle":"2023-08-14T10:09:22.923467Z","shell.execute_reply":"2023-08-14T10:09:22.922291Z"},"papermill":{"duration":126.809817,"end_time":"2023-08-14T10:09:22.925969","exception":false,"start_time":"2023-08-14T10:07:16.116152","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:22.955274Z","iopub.status.busy":"2023-08-14T10:09:22.954300Z","iopub.status.idle":"2023-08-14T10:09:31.472186Z","shell.execute_reply":"2023-08-14T10:09:31.471270Z"},"papermill":{"duration":8.534957,"end_time":"2023-08-14T10:09:31.474781","exception":false,"start_time":"2023-08-14T10:09:22.939824","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = 3,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Main helper function to process documents from the EMR.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param document_type: String denoting the document type to be processed\n    :param document_sections: List of sections for a given document type to process\n    :param split_sentences: Flag to determine whether to further split sections into sentences\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Obtains the sections of the imaging reports and returns only the \n    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n    \"\"\"\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = 3,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Split a document into sentences. Can be used with `sectionize_documents`\n    to further split documents into more manageable pieces. Takes in offsets\n    to ensure that after splitting, the sentences can be matched to the\n    location in the original documents.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param offsets: Iterable tuple of the start and end indices\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:31.556440Z","iopub.status.busy":"2023-08-14T10:09:31.556164Z","iopub.status.idle":"2023-08-14T10:09:31.571938Z","shell.execute_reply":"2023-08-14T10:09:31.571107Z"},"papermill":{"duration":0.034054,"end_time":"2023-08-14T10:09:31.574046","exception":false,"start_time":"2023-08-14T10:09:31.539992","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 16\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:31.602444Z","iopub.status.busy":"2023-08-14T10:09:31.601698Z","iopub.status.idle":"2023-08-14T10:09:31.621434Z","shell.execute_reply":"2023-08-14T10:09:31.620631Z"},"papermill":{"duration":0.036342,"end_time":"2023-08-14T10:09:31.623595","exception":false,"start_time":"2023-08-14T10:09:31.587253","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relevant Title Retrieval","metadata":{}},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\ntrn.head()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:31.650942Z","iopub.status.busy":"2023-08-14T10:09:31.650687Z","iopub.status.idle":"2023-08-14T10:09:31.691013Z","shell.execute_reply":"2023-08-14T10:09:31.689907Z"},"papermill":{"duration":0.058533,"end_time":"2023-08-14T10:09:31.695383","exception":false,"start_time":"2023-08-14T10:09:31.636850","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(SIM_MODEL, device='cuda')\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:31.726783Z","iopub.status.busy":"2023-08-14T10:09:31.725295Z","iopub.status.idle":"2023-08-14T10:09:44.990463Z","shell.execute_reply":"2023-08-14T10:09:44.989410Z"},"papermill":{"duration":13.282604,"end_time":"2023-08-14T10:09:44.992949","exception":false,"start_time":"2023-08-14T10:09:31.710345","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:09:45.023326Z","iopub.status.busy":"2023-08-14T10:09:45.022984Z","iopub.status.idle":"2023-08-14T10:11:20.931589Z","shell.execute_reply":"2023-08-14T10:11:20.929626Z"},"papermill":{"duration":95.926417,"end_time":"2023-08-14T10:11:20.934445","exception":false,"start_time":"2023-08-14T10:09:45.008028","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n_ = gc.collect()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:11:20.983065Z","iopub.status.busy":"2023-08-14T10:11:20.982740Z","iopub.status.idle":"2023-08-14T10:11:31.845868Z","shell.execute_reply":"2023-08-14T10:11:31.844889Z"},"papermill":{"duration":10.891104,"end_time":"2023-08-14T10:11:31.848690","exception":false,"start_time":"2023-08-14T10:11:20.957586","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the top 3 pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 3)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:11:31.924603Z","iopub.status.busy":"2023-08-14T10:11:31.924304Z","iopub.status.idle":"2023-08-14T10:11:55.244590Z","shell.execute_reply":"2023-08-14T10:11:55.243663Z"},"papermill":{"duration":23.339585,"end_time":"2023-08-14T10:11:55.247556","exception":false,"start_time":"2023-08-14T10:11:31.907971","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:11:55.283896Z","iopub.status.busy":"2023-08-14T10:11:55.283599Z","iopub.status.idle":"2023-08-14T10:11:56.143196Z","shell.execute_reply":"2023-08-14T10:11:56.142123Z"},"papermill":{"duration":0.877305,"end_time":"2023-08-14T10:11:56.145444","exception":false,"start_time":"2023-08-14T10:11:55.268139","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Sentences from the Relevant Titles","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n                     columns=['id', 'file'])","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:11:56.178483Z","iopub.status.busy":"2023-08-14T10:11:56.178096Z","iopub.status.idle":"2023-08-14T10:12:01.894786Z","shell.execute_reply":"2023-08-14T10:12:01.893653Z"},"papermill":{"duration":5.737408,"end_time":"2023-08-14T10:12:01.897408","exception":false,"start_time":"2023-08-14T10:11:56.160000","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n## Save memory - delete df since it is no longer necessary\ndel df\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:12:01.930242Z","iopub.status.busy":"2023-08-14T10:12:01.929368Z","iopub.status.idle":"2023-08-14T10:12:02.710141Z","shell.execute_reply":"2023-08-14T10:12:02.709070Z"},"papermill":{"duration":0.799872,"end_time":"2023-08-14T10:12:02.712752","exception":false,"start_time":"2023-08-14T10:12:01.912880","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:12:02.745635Z","iopub.status.busy":"2023-08-14T10:12:02.745316Z","iopub.status.idle":"2023-08-14T10:17:06.706947Z","shell.execute_reply":"2023-08-14T10:17:06.705934Z"},"papermill":{"duration":303.981049,"end_time":"2023-08-14T10:17:06.710072","exception":false,"start_time":"2023-08-14T10:12:02.729023","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parse documents into sentences\nprocessed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:06.745180Z","iopub.status.busy":"2023-08-14T10:17:06.744844Z","iopub.status.idle":"2023-08-14T10:17:11.218048Z","shell.execute_reply":"2023-08-14T10:17:11.217022Z"},"papermill":{"duration":4.491281,"end_time":"2023-08-14T10:17:11.220342","exception":false,"start_time":"2023-08-14T10:17:06.729061","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get embeddings of the wiki text data\nwiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:11.255088Z","iopub.status.busy":"2023-08-14T10:17:11.254041Z","iopub.status.idle":"2023-08-14T10:17:36.345952Z","shell.execute_reply":"2023-08-14T10:17:36.344929Z"},"papermill":{"duration":25.110593,"end_time":"2023-08-14T10:17:36.348422","exception":false,"start_time":"2023-08-14T10:17:11.237829","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:36.382111Z","iopub.status.busy":"2023-08-14T10:17:36.380661Z","iopub.status.idle":"2023-08-14T10:17:36.677809Z","shell.execute_reply":"2023-08-14T10:17:36.676678Z"},"papermill":{"duration":0.315807,"end_time":"2023-08-14T10:17:36.679867","exception":false,"start_time":"2023-08-14T10:17:36.364060","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Combine all answers\ntrn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n\n\n## Search using the prompt and answers to guide the search\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:36.713788Z","iopub.status.busy":"2023-08-14T10:17:36.712233Z","iopub.status.idle":"2023-08-14T10:17:36.728025Z","shell.execute_reply":"2023-08-14T10:17:36.727138Z"},"papermill":{"duration":0.034767,"end_time":"2023-08-14T10:17:36.730378","exception":false,"start_time":"2023-08-14T10:17:36.695611","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings = question_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:36.764917Z","iopub.status.busy":"2023-08-14T10:17:36.763427Z","iopub.status.idle":"2023-08-14T10:17:37.175617Z","shell.execute_reply":"2023-08-14T10:17:37.174423Z"},"papermill":{"duration":0.431343,"end_time":"2023-08-14T10:17:37.177862","exception":false,"start_time":"2023-08-14T10:17:36.746519","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Matching Prompt-Sentence Pairs","metadata":{}},{"cell_type":"code","source":"## Parameter to determine how many relevant sentences to include\nNUM_SENTENCES_INCLUDE = 5\n\n## List containing just Context\ncontexts = []\n\nfor r in tqdm(trn.itertuples(), total=len(trn)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts.append(context)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:37.244626Z","iopub.status.busy":"2023-08-14T10:17:37.243963Z","iopub.status.idle":"2023-08-14T10:17:38.833828Z","shell.execute_reply":"2023-08-14T10:17:38.832943Z"},"papermill":{"duration":1.609553,"end_time":"2023-08-14T10:17:38.836268","exception":false,"start_time":"2023-08-14T10:17:37.226715","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:38.871435Z","iopub.status.busy":"2023-08-14T10:17:38.870861Z","iopub.status.idle":"2023-08-14T10:17:38.875890Z","shell.execute_reply":"2023-08-14T10:17:38.874711Z"},"papermill":{"duration":0.024188,"end_time":"2023-08-14T10:17:38.878394","exception":false,"start_time":"2023-08-14T10:17:38.854206","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:38.910233Z","iopub.status.busy":"2023-08-14T10:17:38.909938Z","iopub.status.idle":"2023-08-14T10:17:38.942436Z","shell.execute_reply":"2023-08-14T10:17:38.941611Z"},"papermill":{"duration":0.050945,"end_time":"2023-08-14T10:17:38.944423","exception":false,"start_time":"2023-08-14T10:17:38.893478","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.015828,"end_time":"2023-08-14T10:17:39.007683","exception":false,"start_time":"2023-08-14T10:17:38.991855","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-se-debertav3-large\"","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:39.041941Z","iopub.status.busy":"2023-08-14T10:17:39.041059Z","iopub.status.idle":"2023-08-14T10:17:39.045484Z","shell.execute_reply":"2023-08-14T10:17:39.044554Z"},"papermill":{"duration":0.023448,"end_time":"2023-08-14T10:17:39.047454","exception":false,"start_time":"2023-08-14T10:17:39.024006","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:39.080034Z","iopub.status.busy":"2023-08-14T10:17:39.079258Z","iopub.status.idle":"2023-08-14T10:17:39.548602Z","shell.execute_reply":"2023-08-14T10:17:39.547612Z"},"papermill":{"duration":0.488286,"end_time":"2023-08-14T10:17:39.551173","exception":false,"start_time":"2023-08-14T10:17:39.062887","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"test_context.csv\")\ntest_df.index = list(range(len(test_df)))\ntest_df.id = list(range(len(test_df)))\ntest_df[\"prompt\"] = test_df[\"context\"] + \" #### \" +  test_df[\"prompt\"]","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:39.585546Z","iopub.status.busy":"2023-08-14T10:17:39.584824Z","iopub.status.idle":"2023-08-14T10:17:39.602541Z","shell.execute_reply":"2023-08-14T10:17:39.601426Z"},"papermill":{"duration":0.037633,"end_time":"2023-08-14T10:17:39.605345","exception":false,"start_time":"2023-08-14T10:17:39.567712","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['answer'] = 'A'\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:39.638617Z","iopub.status.busy":"2023-08-14T10:17:39.637799Z","iopub.status.idle":"2023-08-14T10:17:39.649653Z","shell.execute_reply":"2023-08-14T10:17:39.648811Z"},"papermill":{"duration":0.030584,"end_time":"2023-08-14T10:17:39.651668","exception":false,"start_time":"2023-08-14T10:17:39.621084","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)\nmodel.eval()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:17:39.684625Z","iopub.status.busy":"2023-08-14T10:17:39.683835Z","iopub.status.idle":"2023-08-14T10:18:01.024594Z","shell.execute_reply":"2023-08-14T10:18:01.022741Z"},"papermill":{"duration":21.360878,"end_time":"2023-08-14T10:18:01.027859","exception":false,"start_time":"2023-08-14T10:17:39.666981","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:01.079858Z","iopub.status.busy":"2023-08-14T10:18:01.079031Z","iopub.status.idle":"2023-08-14T10:18:01.085479Z","shell.execute_reply":"2023-08-14T10:18:01.084471Z"},"papermill":{"duration":0.033179,"end_time":"2023-08-14T10:18:01.087489","exception":false,"start_time":"2023-08-14T10:18:01.054310","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:01.120666Z","iopub.status.busy":"2023-08-14T10:18:01.119926Z","iopub.status.idle":"2023-08-14T10:18:01.127389Z","shell.execute_reply":"2023-08-14T10:18:01.126425Z"},"papermill":{"duration":0.026162,"end_time":"2023-08-14T10:18:01.129276","exception":false,"start_time":"2023-08-14T10:18:01.103114","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:01.163853Z","iopub.status.busy":"2023-08-14T10:18:01.162905Z","iopub.status.idle":"2023-08-14T10:18:01.173494Z","shell.execute_reply":"2023-08-14T10:18:01.172483Z"},"papermill":{"duration":0.030447,"end_time":"2023-08-14T10:18:01.175589","exception":false,"start_time":"2023-08-14T10:18:01.145142","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer)\n)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:01.209840Z","iopub.status.busy":"2023-08-14T10:18:01.209548Z","iopub.status.idle":"2023-08-14T10:18:01.683103Z","shell.execute_reply":"2023-08-14T10:18:01.682032Z"},"papermill":{"duration":0.493618,"end_time":"2023-08-14T10:18:01.685989","exception":false,"start_time":"2023-08-14T10:18:01.192371","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:01.719768Z","iopub.status.busy":"2023-08-14T10:18:01.718895Z","iopub.status.idle":"2023-08-14T10:18:02.802181Z","shell.execute_reply":"2023-08-14T10:18:02.801216Z"},"papermill":{"duration":1.101895,"end_time":"2023-08-14T10:18:02.804298","exception":false,"start_time":"2023-08-14T10:18:01.702403","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_test_ds)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:18:02.839409Z","iopub.status.busy":"2023-08-14T10:18:02.837848Z","iopub.status.idle":"2023-08-14T10:19:17.681195Z","shell.execute_reply":"2023-08-14T10:19:17.680061Z"},"papermill":{"duration":74.862571,"end_time":"2023-08-14T10:19:17.683318","exception":false,"start_time":"2023-08-14T10:18:02.820747","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({\"id\": np.arange(len(test_df))})\nsubmission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n\nsubmission_df.head()","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:19:17.717465Z","iopub.status.busy":"2023-08-14T10:19:17.717133Z","iopub.status.idle":"2023-08-14T10:19:17.731009Z","shell.execute_reply":"2023-08-14T10:19:17.729803Z"},"papermill":{"duration":0.033576,"end_time":"2023-08-14T10:19:17.733491","exception":false,"start_time":"2023-08-14T10:19:17.699915","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Once we write our submission file we're good to submit!\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2023-08-14T10:19:17.769853Z","iopub.status.busy":"2023-08-14T10:19:17.769003Z","iopub.status.idle":"2023-08-14T10:19:17.775472Z","shell.execute_reply":"2023-08-14T10:19:17.774541Z"},"papermill":{"duration":0.026091,"end_time":"2023-08-14T10:19:17.777618","exception":false,"start_time":"2023-08-14T10:19:17.751527","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}